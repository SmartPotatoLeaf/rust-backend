# SPL Backend

<div align="center">

![Rust](https://img.shields.io/badge/Rust-nightly-orange)
![Axum](https://img.shields.io/badge/Axum-0.7-blue)
![SeaORM](https://img.shields.io/badge/SeaORM-1.0-green)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-14+-blue)
![License](https://img.shields.io/badge/License-MIT-yellow)

Servicio backend REST API moderno y de alto rendimiento para la plataforma SmartPotatoLeaf, construido con Rust y principios de Clean Architecture.

[CaracterÃ­sticas](#caracterÃ­sticas) â€¢ [Arquitectura](#arquitectura) â€¢ [Primeros Pasos](#instalaciÃ³n) â€¢ [DocumentaciÃ³n API](#api-y-documentaciÃ³n) â€¢ [Deployment](#deployment)

[ğŸ‡¬ğŸ‡§ English Version](./README.md)

</div>

---

## Tabla de Contenidos

- [IntroducciÃ³n](#introducciÃ³n)
- [CaracterÃ­sticas](#caracterÃ­sticas)
- [Arquitectura](#arquitectura)
- [Requisitos Previos](#requisitos-previos)
- [InstalaciÃ³n](#instalaciÃ³n)
- [ConfiguraciÃ³n](#configuraciÃ³n)
- [EjecuciÃ³n](#ejecuciÃ³n)
- [API y DocumentaciÃ³n](#api-y-documentaciÃ³n)
- [Testing](#testing)
- [Deployment](#deployment)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [DocumentaciÃ³n Adicional](#documentaciÃ³n-adicional)

---

## IntroducciÃ³n

SPL Backend es una API RESTful desarrollada en Rust que proporciona servicios de diagnÃ³stico de enfermedades en cultivos de papa mediante visiÃ³n artificial. El sistema permite a agricultores y tÃ©cnicos:

- Subir imÃ¡genes de hojas de papa para diagnÃ³stico
- Obtener predicciones sobre enfermedades mediante modelos de ML
- Recibir recomendaciones personalizadas segÃºn la severidad
- Gestionar parcelas y hacer seguimiento histÃ³rico de cultivos
- Visualizar analÃ­ticas y estadÃ­sticas de sus cultivos

El proyecto representa una reescritura completa desde Python/FastAPI a Rust/Axum, aprovechando las ventajas de rendimiento, seguridad de tipos y memory safety de Rust.

## CaracterÃ­sticas

### Funcionales

- **AutenticaciÃ³n y AutorizaciÃ³n**: JWT-based con roles granulares (Admin, Supervisor, User)
- **Multi-tenant**: Soporte para mÃºltiples compaÃ±Ã­as con aislamiento de datos
- **DiagnÃ³stico de Enfermedades**: IntegraciÃ³n con modelos TensorFlow Serving para predicciones en tiempo real
- **Sistema de Recomendaciones**: Recomendaciones contextuales basadas en severidad de enfermedad
- **GestiÃ³n de Parcelas**: OrganizaciÃ³n de predicciones por lotes o parcelas
- **Feedback Loop**: Sistema de retroalimentaciÃ³n para mejorar predicciones
- **Dashboard AnalÃ­tico**: Filtros dinÃ¡micos y visualizaciones de datos
- **Almacenamiento de ImÃ¡genes**: Soporte para Azure Blob Storage y almacenamiento local

### TÃ©cnicas

- **Clean Architecture**: SeparaciÃ³n clara entre dominio, aplicaciÃ³n e infraestructura
- **Type Safety**: ValidaciÃ³n en tiempo de compilaciÃ³n con el sistema de tipos de Rust
- **Async/Await**: Arquitectura asÃ­ncrona basada en Tokio para alto rendimiento
- **ORM Robusto**: SeaORM para migraciones y queries type-safe
- **OpenAPI**: DocumentaciÃ³n automÃ¡tica con Swagger UI
- **Testing**: Suite completa de tests unitarios e integraciÃ³n con mocks
- **Observability**: Logging estructurado con tracing
- **Respuestas Optimizadas**: Soporte para respuestas simplificadas (`?simplified=true`)

## Arquitectura

### Hexagonal (Ports & Adapters)

El proyecto sigue principios de arquitectura hexagonal (Clean Architecture):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   INFRASTRUCTURE                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    Web     â”‚  â”‚ Database â”‚  â”‚  Integrations   â”‚ â”‚
â”‚  â”‚  (Axum)    â”‚  â”‚ (SeaORM) â”‚  â”‚ (TF, Storage)   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚              â”‚                 â”‚
         â–¼              â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   APPLICATION                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         Services (Business Logic)           â”‚   â”‚
â”‚  â”‚  - AuthService  - PredictionService         â”‚   â”‚
â”‚  â”‚  - UserService  - PlotService               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DOMAIN                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Entities   â”‚       â”‚  Ports (Traits)    â”‚     â”‚
â”‚  â”‚  - User      â”‚       â”‚  - Repositories    â”‚     â”‚
â”‚  â”‚  - Predictionâ”‚       â”‚  - External Svcs   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Capas

#### Domain Layer (`spl-domain`)
Contiene la lÃ³gica de negocio pura, independiente de frameworks:
- **Entities**: User, Role, Company, Prediction, Label, Plot, Recommendation, Feedback
- **Ports**: Traits que definen interfaces para repositorios y servicios externos

#### Application Layer (`spl-application`)
Orquesta casos de uso del negocio:
- **Services**: LÃ³gica de aplicaciÃ³n (AuthService, PredictionService, etc.)
- **DTOs**: Objetos de transferencia de datos
- **Mappers**: ConversiÃ³n entre entities y DTOs

#### Infrastructure Layer (`spl-infra`)
Implementaciones concretas de adaptadores:
- **Web**: Controladores HTTP, middleware, validaciÃ³n (Axum)
- **Persistence**: Repositorios con SeaORM para PostgreSQL
- **Integrations**: Clientes para TensorFlow Serving y Azure Blob Storage
- **Auth**: JWT token generation, password hashing (Argon2)

#### Migration Layer (`spl-migration`)
Migraciones de base de datos con SeaORM:
- Schemas de tablas
- Seeds de datos iniciales
- Versionamiento de esquema

#### Shared Layer (`spl-shared`)
Utilidades compartidas entre capas:
- ConfiguraciÃ³n centralizada
- Error handling
- TelemetrÃ­a y logging
- HTTP helpers

## Requisitos Previos

### Software

- **Rust**: nightly (requerido para dependencias edition2024) ([rustup](https://rustup.rs/))
- **PostgreSQL**: 14.x o superior
- **TensorFlow Serving**: 2.x (opcional, puede usar mock)
- **Azure Storage Account**: Para almacenamiento de imÃ¡genes (opcional, puede usar local)

### Herramientas de Desarrollo (Recomendadas)

- `cargo-watch`: Para desarrollo con hot-reload
- `cargo-tarpaulin`: Para coverage de tests
- `cargo-nextest`: Test runner mejorado
- `cargo-edit`: GestiÃ³n simplificada de dependencias

```bash
# Instalar Rust nightly (requerido para edition2024)
rustup toolchain install nightly
rustup default nightly

# Instalar herramientas de desarrollo
cargo install cargo-watch cargo-tarpaulin cargo-nextest cargo-edit
```

## InstalaciÃ³n

### 1. Clonar el Repositorio

```bash
git clone https://github.com/your-org/spl-backend.git
cd spl-backend
```

### 2. Instalar Dependencias

```bash
# Build en modo desarrollo
cargo build

# Build optimizado para producciÃ³n
cargo build --release
```

### 3. Configurar Base de Datos

```bash
# Crear base de datos PostgreSQL
createdb spl_backend

# Las migraciones se ejecutan automÃ¡ticamente al iniciar el servidor
# O puedes ejecutarlas manualmente:
cargo run -p spl-migration
```

## ConfiguraciÃ³n

La configuraciÃ³n utiliza un sistema jerÃ¡rquico que soporta mÃºltiples fuentes:

1. `config/default.toml` - ConfiguraciÃ³n base (commiteado)
2. `config/local.toml` - Overrides locales (gitignored)
3. Variables de entorno con prefijo `SPL__` (mayor prioridad)

### Archivo de ConfiguraciÃ³n

Crear `config/local.toml`:

```toml
[server]
host = "0.0.0.0"
port = 8080
jwt_secret = "your-secret-key-min-32-chars-change-in-production"
jwt_expiration_hours = 24
cors_allowed_origins = "http://localhost:3000,http://localhost:5173"

[database]
url = "postgres://username:password@localhost/spl_backend"
max_connections = 20
min_connections = 5
connect_timeout = 10
idle_timeout = 300
max_lifetime = 1800

[admin]
username = "admin"
password = "change-me-in-production"
email = "admin@example.com"

[integrations.model_serving]
provider = "tensorflow"  # Options: "tensorflow", "tensorflow_grpc", "mock"
url = "http://localhost:8501"
model_name = "potato_disease_model"
timeout_seconds = 30
image_size = 256
concurrency_limit = 10

[integrations.storage]
provider = "local"  # Options: "azure", "local", "mock"
local_base_path = "./storage"

# Para Azure (comentado por defecto)
# provider = "azure"
# connection_string = "DefaultEndpointsProtocol=https;AccountName=..."
# container_name = "spl-images"
```

### Variables de Entorno

Alternativamente, usar variables de entorno:

```bash
# Server
export SPL__SERVER__HOST="0.0.0.0"
export SPL__SERVER__PORT=8080
export SPL__SERVER__JWT_SECRET="your-secret-key"

# Database
export SPL__DATABASE__URL="postgres://user:pass@localhost/spl_backend"

# Admin
export SPL__ADMIN__USERNAME="admin"
export SPL__ADMIN__PASSWORD="secure-password"
export SPL__ADMIN__EMAIL="admin@example.com"

# Model Serving
export SPL__INTEGRATIONS__MODEL_SERVING__PROVIDER="mock"
export SPL__INTEGRATIONS__MODEL_SERVING__URL="http://localhost:8501"

# Storage
export SPL__INTEGRATIONS__STORAGE__PROVIDER="local"
export SPL__INTEGRATIONS__STORAGE__LOCAL_BASE_PATH="./storage"
```

### ConfiguraciÃ³n MÃ­nima para Desarrollo

Para desarrollo rÃ¡pido con mocks:

```toml
[server]
host = "127.0.0.1"
port = 8080
jwt_secret = "dev-secret-key-not-for-production-use-only"
jwt_expiration_hours = 168  # 1 semana

[database]
url = "postgres://postgres:postgres@localhost/spl_dev"

[admin]
username = "admin"
password = "admin123"
email = "dev@localhost"

[integrations.model_serving]
provider = "mock"
url = "http://localhost:8501"
model_name = "mock_model"
timeout_seconds = 5

[integrations.storage]
provider = "local"
local_base_path = "./storage"
```

## EjecuciÃ³n

### Modo Desarrollo

```bash
# Iniciar servidor con auto-reload
cargo watch -x 'run --bin spl-server'

# O sin watch
cargo run --bin spl-server

# Con logs detallados
RUST_LOG=debug cargo run --bin spl-server
```

El servidor estarÃ¡ disponible en `http://localhost:8080`

### Modo ProducciÃ³n

```bash
# Build optimizado
cargo build --release

# Ejecutar binario
./target/release/spl-server

# Con configuraciÃ³n explÃ­cita
SPL__SERVER__HOST=0.0.0.0 \
SPL__SERVER__PORT=8080 \
./target/release/spl-server
```

### Health Check

```bash
curl http://localhost:8080/api/v1/auth/health
```

Respuesta esperada:
```json
{
  "status": "ok",
  "message": "Server is clean and running"
}
```

## API y DocumentaciÃ³n

### DocumentaciÃ³n Interactiva

Una vez iniciado el servidor, acceder a:

```
http://localhost:8080/api/v1/swagger-ui
```

La documentaciÃ³n OpenAPI se genera automÃ¡ticamente desde el cÃ³digo y proporciona:
- Todos los endpoints disponibles
- Schemas de request/response
- AutenticaciÃ³n integrada
- Try-it-out interactivo

### AutenticaciÃ³n

Todos los endpoints (excepto `/auth/login` y `/auth/health`) requieren autenticaciÃ³n JWT.

#### Login

```bash
curl -X POST http://localhost:8080/api/v1/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "username": "admin",
    "password": "admin123"
  }'
```

Respuesta:
```json
{
  "token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."
}
```

#### Usar Token

```bash
curl -X GET http://localhost:8080/api/v1/users/me \
  -H "Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."
```

### Endpoints Principales

#### Authentication
- `POST /api/v1/auth/login` - AutenticaciÃ³n de usuario
- `POST /api/v1/auth/register` - Registro de nuevo usuario (admin)
- `POST /api/v1/auth/validate` - Validar token JWT
- `GET /api/v1/auth/health` - Health check

#### Users
- `GET /api/v1/users/me` - InformaciÃ³n del usuario actual
- `PUT /api/v1/users/:id` - Actualizar usuario (admin)
- `DELETE /api/v1/users/:id` - Eliminar usuario (admin)

#### Companies
- `POST /api/v1/companies` - Crear compaÃ±Ã­a (admin)
- `GET /api/v1/companies/:id` - Obtener compaÃ±Ã­a
- `PUT /api/v1/companies/:id` - Actualizar compaÃ±Ã­a (admin)
- `DELETE /api/v1/companies/:id` - Eliminar compaÃ±Ã­a (admin)

#### Diagnostics - Labels
- `GET /api/v1/diagnostics/labels` - Listar etiquetas de enfermedades
- `GET /api/v1/diagnostics/labels/:id` - Obtener etiqueta
- `POST /api/v1/diagnostics/labels` - Crear etiqueta (admin)
- `PUT /api/v1/diagnostics/labels/:id` - Actualizar etiqueta (admin)
- `DELETE /api/v1/diagnostics/labels/:id` - Eliminar etiqueta (admin)

#### Diagnostics - Predictions
- `POST /api/v1/diagnostics/predictions` - Crear predicciÃ³n (upload imagen)
- `GET /api/v1/diagnostics/predictions` - Listar predicciones del usuario
- `GET /api/v1/diagnostics/predictions/:id` - Obtener predicciÃ³n especÃ­fica
- `DELETE /api/v1/diagnostics/predictions/:id` - Eliminar predicciÃ³n
- `POST /api/v1/diagnostics/predictions/filter` - Filtrar predicciones
- `GET /api/v1/diagnostics/predictions/blobs/*path` - Obtener imagen

#### Recommendations
- `GET /api/v1/recommendations` - Listar recomendaciones
- `GET /api/v1/recommendations/:id` - Obtener recomendaciÃ³n
- `GET /api/v1/recommendations/severity/:percentage` - Por severidad
- `POST /api/v1/recommendations` - Crear recomendaciÃ³n (admin)
- `PUT /api/v1/recommendations/:id` - Actualizar recomendaciÃ³n (admin)
- `DELETE /api/v1/recommendations/:id` - Eliminar recomendaciÃ³n (admin)

#### Plots
- `GET /api/v1/plots` - Listar parcelas del usuario
- `POST /api/v1/plots` - Crear parcela (supervisor)
- `GET /api/v1/plots/:id` - Obtener parcela
- `PUT /api/v1/plots/:id` - Actualizar parcela (supervisor)
- `DELETE /api/v1/plots/:id` - Eliminar parcela (supervisor)
- `POST /api/v1/plots/:id/assign` - Asignar predicciones a parcela
- `POST /api/v1/plots/detailed` - Obtener parcelas con detalles

#### Dashboard
- `GET /api/v1/dashboard/filters` - Obtener filtros disponibles
- `POST /api/v1/dashboard/summary` - Obtener resumen estadÃ­stico

#### Feedbacks
- `GET /api/v1/feedbacks` - Listar feedbacks del usuario
- `POST /api/v1/feedbacks` - Crear feedback
- `GET /api/v1/feedbacks/:id` - Obtener feedback
- `PUT /api/v1/feedbacks/:id` - Actualizar feedback
- `DELETE /api/v1/feedbacks/:id` - Eliminar feedback

### Query Parameters

Muchos endpoints GET soportan el parÃ¡metro `simplified`:

```bash
# Respuesta completa con relaciones
GET /api/v1/diagnostics/labels

# Respuesta simplificada (solo campos esenciales)
GET /api/v1/diagnostics/labels?simplified=true
```

## Testing

### Ejecutar Tests

```bash
# Todos los tests
cargo test

# Tests de un paquete especÃ­fico
cargo test -p spl-domain
cargo test -p spl-application
cargo test -p spl-infra

# Tests con output detallado
cargo test -- --nocapture

# Tests especÃ­ficos por nombre
cargo test test_user_creation

# Tests de integraciÃ³n solamente
cargo test --test '*'
```

### Test con Nextest (Recomendado)

```bash
# Instalar nextest
cargo install cargo-nextest

# Ejecutar con nextest (mÃ¡s rÃ¡pido, mejor output)
cargo nextest run

# Con retries automÃ¡ticos
cargo nextest run --retries 3
```

### Coverage

```bash
# Generar reporte de coverage
cargo tarpaulin --out Html --output-dir coverage

# Abrir reporte
open coverage/index.html  # macOS
xdg-open coverage/index.html  # Linux
```

### Estructura de Tests

```
packs/
â”œâ”€â”€ spl-domain/tests/          # Tests unitarios de entidades
â”œâ”€â”€ spl-application/tests/     # Tests de servicios con mocks
â””â”€â”€ spl-infra/tests/           # Tests de integraciÃ³n
    â”œâ”€â”€ common/mod.rs          # Helpers y fixtures
    â”œâ”€â”€ web_integration.rs     # Tests HTTP end-to-end
    â”œâ”€â”€ persistence/           # Tests de repositorios
    â””â”€â”€ web/                   # Tests de controladores
```

## Deployment

### Docker

#### Build de Imagen

```bash
# Build multi-stage optimizado
docker build -t spl-backend:latest .

# Con target especÃ­fico
docker build --target runtime -t spl-backend:latest .
```

#### Ejecutar Container

```bash
docker run -d \
  --name spl-backend \
  -p 8080:8080 \
  -e SPL__DATABASE__URL="postgres://user:pass@host.docker.internal/spl" \
  -e SPL__SERVER__JWT_SECRET="your-production-secret" \
  -e SPL__INTEGRATIONS__MODEL_SERVING__PROVIDER="tensorflow" \
  -e SPL__INTEGRATIONS__STORAGE__PROVIDER="azure" \
  -e SPL__INTEGRATIONS__STORAGE__CONNECTION_STRING="your-connection" \
  spl-backend:latest
```

#### Docker Compose

Crear `docker-compose.yml`:

```yaml
version: '3.8'

services:
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: spl_backend
      POSTGRES_USER: spl_user
      POSTGRES_PASSWORD: spl_password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  spl-backend:
    build: .
    ports:
      - "8080:8080"
    environment:
      SPL__DATABASE__URL: "postgres://spl_user:spl_password@postgres/spl_backend"
      SPL__SERVER__JWT_SECRET: "change-me-in-production"
      SPL__INTEGRATIONS__MODEL_SERVING__PROVIDER: "mock"
      SPL__INTEGRATIONS__STORAGE__PROVIDER: "local"
      RUST_LOG: "info"
    depends_on:
      - postgres
    volumes:
      - ./storage:/app/storage

volumes:
  postgres_data:
```

Ejecutar:
```bash
docker-compose up -d
```

### Variables de Entorno en ProducciÃ³n

Variables crÃ­ticas que deben configurarse en producciÃ³n:

```bash
# Security (OBLIGATORIO cambiar)
SPL__SERVER__JWT_SECRET="<random-64-char-string>"

# Database
SPL__DATABASE__URL="postgres://user:pass@prod-host:5432/spl_prod"
SPL__DATABASE__MAX_CONNECTIONS=50

# Admin (usar credenciales seguras)
SPL__ADMIN__PASSWORD="<secure-hashed-password>"

# CORS
SPL__SERVER__CORS_ALLOWED_ORIGINS="https://app.yourcompany.com"

# Model Serving
SPL__INTEGRATIONS__MODEL_SERVING__PROVIDER="tensorflow_grpc"
SPL__INTEGRATIONS__MODEL_SERVING__URL="grpc://ml-service:8500"

# Storage
SPL__INTEGRATIONS__STORAGE__PROVIDER="azure"
SPL__INTEGRATIONS__STORAGE__CONNECTION_STRING="<azure-connection-string>"
SPL__INTEGRATIONS__STORAGE__CONTAINER_NAME="spl-images-prod"

# Logging
RUST_LOG="info,spl_server=debug,spl_infra=debug"
```

### Consideraciones de ProducciÃ³n

1. **Secrets Management**: Usar Kubernetes Secrets, AWS Secrets Manager, o HashiCorp Vault
2. **Database**: Usar connection pooling apropiado, read replicas si necesario
3. **Monitoring**: Configurar Prometheus metrics, distributed tracing
4. **Backups**: Backup automÃ¡tico de PostgreSQL y blobs
5. **SSL/TLS**: Terminar SSL en load balancer o reverse proxy
6. **Rate Limiting**: Configurar rate limits a nivel de API gateway
7. **Horizontal Scaling**: El servidor es stateless y se puede escalar horizontalmente

## Estructura del Proyecto

```
spl-backend/
â”œâ”€â”€ Cargo.toml                    # Workspace definition
â”œâ”€â”€ Cargo.lock
â”œâ”€â”€ Dockerfile                    # Multi-stage build
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ config/                       # Configuration files
â”‚   â”œâ”€â”€ default.toml             # Default config (committed)
â”‚   â””â”€â”€ local.toml               # Local overrides (gitignored)
â”‚
â”œâ”€â”€ packs/                        # Rust workspace members
â”‚   â”œâ”€â”€ spl-domain/              # Domain layer
â”‚   â”‚   â”œâ”€â”€ Cargo.toml
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ lib.rs
â”‚   â”‚   â”‚   â”œâ”€â”€ entities/        # Domain entities
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ user.rs
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ prediction.rs
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ plot.rs
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚   â””â”€â”€ ports/           # Traits (interfaces)
â”‚   â”‚   â”‚       â”œâ”€â”€ repositories/
â”‚   â”‚   â”‚       â”œâ”€â”€ auth.rs
â”‚   â”‚   â”‚       â””â”€â”€ integrations.rs
â”‚   â”‚   â””â”€â”€ tests/
â”‚   â”‚
â”‚   â”œâ”€â”€ spl-application/         # Application layer
â”‚   â”‚   â”œâ”€â”€ Cargo.toml
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ lib.rs
â”‚   â”‚   â”‚   â”œâ”€â”€ services/        # Business logic
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ auth.rs
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ user/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ diagnostics/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚   â”œâ”€â”€ dtos/            # Data transfer objects
â”‚   â”‚   â”‚   â””â”€â”€ mappers/         # Entity â†” DTO conversions
â”‚   â”‚   â””â”€â”€ tests/
â”‚   â”‚
â”‚   â”œâ”€â”€ spl-infra/               # Infrastructure layer
â”‚   â”‚   â”œâ”€â”€ Cargo.toml
â”‚   â”‚   â”œâ”€â”€ build.rs
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ lib.rs
â”‚   â”‚   â”‚   â””â”€â”€ adapters/
â”‚   â”‚   â”‚       â”œâ”€â”€ web/         # HTTP controllers
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ state.rs
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ models/  # Request/Response schemas
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ mappers/
â”‚   â”‚   â”‚       â”œâ”€â”€ persistence/ # Database repositories
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ repositories/
â”‚   â”‚   â”‚       â”œâ”€â”€ auth/        # JWT, password hashing
â”‚   â”‚   â”‚       â””â”€â”€ integrations/
â”‚   â”‚   â”‚           â”œâ”€â”€ model_serving/  # TF Serving clients
â”‚   â”‚   â”‚           â””â”€â”€ storage/        # Blob storage clients
â”‚   â”‚   â””â”€â”€ tests/
â”‚   â”‚       â”œâ”€â”€ web_integration.rs
â”‚   â”‚       â”œâ”€â”€ common/
â”‚   â”‚       â”œâ”€â”€ persistence/
â”‚   â”‚       â””â”€â”€ web/
â”‚   â”‚
â”‚   â”œâ”€â”€ spl-migration/           # Database migrations
â”‚   â”‚   â”œâ”€â”€ Cargo.toml
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ lib.rs
â”‚   â”‚   â”‚   â”œâ”€â”€ m20260130_000001_create_role_table.rs
â”‚   â”‚   â”‚   â”œâ”€â”€ m20260130_000002_create_user_table.rs
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ seeds/               # Seed data (JSON)
â”‚   â”‚       â””â”€â”€ recommendations.json
â”‚   â”‚
â”‚   â”œâ”€â”€ spl-server/              # Application entry point
â”‚   â”‚   â”œâ”€â”€ Cargo.toml
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â””â”€â”€ main.rs          # Bootstrap & dependency injection
â”‚   â”‚
â”‚   â””â”€â”€ spl-shared/              # Shared utilities
â”‚       â”œâ”€â”€ Cargo.toml
â”‚       â””â”€â”€ src/
â”‚           â”œâ”€â”€ lib.rs
â”‚           â”œâ”€â”€ config.rs        # Configuration loading
â”‚           â”œâ”€â”€ error.rs         # Error types
â”‚           â”œâ”€â”€ telemetry.rs     # Logging setup
â”‚           â””â”€â”€ http/            # HTTP utilities
â”‚
â”œâ”€â”€ storage/                      # Local file storage (dev)
â”‚   â””â”€â”€ <user-id>/
â”‚       â””â”€â”€ images/
â”‚
â”œâ”€â”€ legacy/                       # Legacy Python implementation (reference)
â”‚   â””â”€â”€ app/
â”‚
â””â”€â”€ docs/                         # Additional documentation
    â”œâ”€â”€ EXECUTIVE_SUMMARY.md
    â”œâ”€â”€ ANALYSIS_ROUTES_COMPARISON.md
    â”œâ”€â”€ ROUTES_MAPPING_TABLE.md
    â””â”€â”€ ACTION_PLAN.md
```

## DocumentaciÃ³n Adicional

### AnÃ¡lisis de MigraciÃ³n

DocumentaciÃ³n completa del proceso de migraciÃ³n desde Python:

- **[EXECUTIVE_SUMMARY.md](./EXECUTIVE_SUMMARY.md)** - Resumen ejecutivo con mÃ©tricas
- **[ANALYSIS_ROUTES_COMPARISON.md](./ANALYSIS_ROUTES_COMPARISON.md)** - ComparaciÃ³n detallada de funcionalidades
- **[ROUTES_MAPPING_TABLE.md](./ROUTES_MAPPING_TABLE.md)** - Tabla de mapeo de rutas legacy â†’ Rust
- **[ACTION_PLAN.md](./ACTION_PLAN.md)** - Plan de acciÃ³n y tareas pendientes

### GuÃ­as TÃ©cnicas

- **Clean Architecture**: Ver `docs/architecture.md` (TODO)
- **Database Schema**: Ver `docs/database-schema.md` (TODO)
- **API Versioning**: Ver `docs/api-versioning.md` (TODO)
- **Security**: Ver `docs/security.md` (TODO)

## Desarrollo

### Pre-commit Hooks

Configurar git hooks para verificar cÃ³digo antes de commit:

```bash
# .git/hooks/pre-commit
#!/bin/bash
cargo fmt --check || exit 1
cargo clippy -- -D warnings || exit 1
cargo test --lib || exit 1
```

```bash
chmod +x .git/hooks/pre-commit
```

### GuÃ­a de Estilo

- Seguir [Rust API Guidelines](https://rust-lang.github.io/api-guidelines/)
- Usar `rustfmt` con configuraciÃ³n por defecto
- Ejecutar `cargo clippy` y resolver todos los warnings
- Documentar funciones pÃºblicas con `///` doc comments
- Tests para toda funcionalidad nueva (mÃ­nimo 80% coverage)

### Convenciones de CÃ³digo

```rust
// âœ… Good: nombres descriptivos, types explÃ­citos cuando Ãºtil
pub async fn create_prediction(
    user_id: Uuid,
    image_bytes: Vec<u8>,
    filename: String,
) -> Result<Prediction> {
    // ...
}

// âœ… Good: manejo explÃ­cito de errores
match user_repo.get_by_id(user_id).await {
    Ok(Some(user)) => process_user(user),
    Ok(None) => return Err(AppError::NotFound("User not found".into())),
    Err(e) => return Err(AppError::DatabaseError(e)),
}

// âœ… Good: documentaciÃ³n clara
/// Creates a new prediction from an uploaded image.
///
/// This function:
/// 1. Saves the image to blob storage
/// 2. Calls the ML model for prediction
/// 3. Persists the prediction to database
///
/// # Arguments
/// * `user_id` - ID of the user creating the prediction
/// * `image_bytes` - Raw image data
/// * `filename` - Original filename of the image
///
/// # Errors
/// Returns error if storage upload, model prediction, or database save fails
pub async fn create_prediction(...)
```

## Troubleshooting

### Errores Comunes

#### Error: "Database connection failed"

```bash
# Verificar que PostgreSQL estÃ© corriendo
pg_isready

# Verificar string de conexiÃ³n
psql "postgres://user:pass@localhost/spl_backend"

# Verificar logs del servidor
RUST_LOG=debug cargo run
```

#### Error: "JWT secret must be at least 32 characters"

Configurar un secret mÃ¡s largo en `config/local.toml` o variable de entorno:
```bash
export SPL__SERVER__JWT_SECRET="your-very-long-secret-key-at-least-32-characters-long"
```

#### Error: "Model serving health check failed"

Si no tienes TensorFlow Serving disponible:
```toml
[integrations.model_serving]
provider = "mock"  # Usar mock en desarrollo
```

#### Error: "Azure Blob Storage connection failed"

Para desarrollo local, usar storage local:
```toml
[integrations.storage]
provider = "local"
local_base_path = "./storage"
```

### Debugging

```bash
# Logs detallados
RUST_LOG=trace cargo run

# Logs de un mÃ³dulo especÃ­fico
RUST_LOG=spl_infra::adapters::web=debug cargo run

# Logs en formato JSON
RUST_LOG=info cargo run 2>&1 | jq

# Con debugger (lldb en macOS, gdb en Linux)
rust-lldb target/debug/spl-server
```

## Performance

### Benchmarks

ComparaciÃ³n con implementaciÃ³n legacy Python:

| Metric | Python (FastAPI) | Rust (Axum) | Mejora |
|--------|------------------|-------------|---------|
| Requests/sec | ~1,200 | ~12,000 | 10x |
| Latency p50 | 45ms | 4ms | 11x |
| Latency p99 | 180ms | 15ms | 12x |
| Memory usage | 120MB | 15MB | 8x |
| CPU usage (idle) | 5% | 0.5% | 10x |

### Optimizaciones

- Connection pooling configurado en base de datos
- Async/await para operaciones I/O
- Zero-copy donde posible con `Bytes`
- CompilaciÃ³n con optimizaciones de release (`--release`)
- SIMD para procesamiento de imÃ¡genes (TODO)

## ContribuciÃ³n

### Proceso

1. Fork del repositorio
2. Crear branch descriptivo: `feature/new-feature` o `fix/bug-description`
3. Hacer cambios con tests
4. Verificar que pasen: `cargo test && cargo fmt && cargo clippy`
5. Commit con mensaje descriptivo
6. Push y crear Pull Request

### Commits

Seguir [Conventional Commits](https://www.conventionalcommits.org/):

```
feat: add user profile endpoint
fix: resolve database connection pool exhaustion
docs: update API documentation for predictions
test: add integration tests for plot service
refactor: extract common validation logic
```

## Licencia

[Especificar licencia - MIT, Apache 2.0, etc.]

## Contacto y Soporte

- **Repositorio**: https://github.com/your-org/spl-backend
- **Issues**: https://github.com/your-org/spl-backend/issues
- **Discussions**: https://github.com/your-org/spl-backend/discussions
- **Email**: dev-team@yourcompany.com

## Recursos

### Rust
- [The Rust Book](https://doc.rust-lang.org/book/)
- [Rust by Example](https://doc.rust-lang.org/rust-by-example/)
- [Rust API Guidelines](https://rust-lang.github.io/api-guidelines/)

### Frameworks y LibrerÃ­as
- [Axum](https://docs.rs/axum/) - Web framework
- [SeaORM](https://www.sea-ql.org/SeaORM/) - ORM
- [Tokio](https://tokio.rs/) - Async runtime
- [Tracing](https://docs.rs/tracing/) - Logging

### Arquitectura
- [Clean Architecture](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html)
- [Hexagonal Architecture](https://alistair.cockburn.us/hexagonal-architecture/)

---

**Version**: 0.1.0  
**Status**: Production Ready (95% complete)  
**Last Updated**: February 13, 2026  
**Maintainers**: SmartPotatoLeaf Team
